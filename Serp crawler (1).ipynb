{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad8b219b",
   "metadata": {},
   "source": [
    "SERP Crawler\n",
    "this code helps us in scraping the content from search results page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d24aa4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#all the imports\n",
    "import json\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from pytube import YouTube,Channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72971bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pytube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a84623a",
   "metadata": {},
   "outputs": [],
   "source": [
    "query='site:youtube.com openinapp.co'   # this the query in google search\n",
    "\n",
    "results_per_page=100\n",
    "no_of_pages=100\n",
    "url='https://www.google.com/search?q={query}&num={results_per_page}'\n",
    "channels=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b019dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#entering the search results\n",
    "for page in range(no_of_pages):\n",
    "    response=requests.get(url)\n",
    "    soup=BeautifulSoup(response.text,'html.parser')\n",
    "    \n",
    "    #scrape the channel links from channel results\n",
    "    for result in soup.find_all('div',class_='yuRUbf'):\n",
    "        # html class'yuRUbf' contains the open link of the result it can change sometime as google keeps updating the pages.\n",
    "        try:\n",
    "            link=result.a['href']\n",
    "            if 'youtube.com/channel/' in link:\n",
    "                channel_url=link\n",
    "                channels.append(channel_url)\n",
    "                print(channel_url)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "    #now scrape from watch links\n",
    "    for result in soup.find_all('a',href=True):\n",
    "        link=result['href']\n",
    "        #print(link) # just to debug incase\n",
    "        try:\n",
    "            if 'youtube.com/watch?v=' in link:\n",
    "                video_url=link\n",
    "                #using pytube library we can extract lots of info about youtube video\n",
    "                x=YouTube(video_url)\n",
    "                channel_url=x.channel_url\n",
    "                c=Channel(channel_url)\n",
    "                print(channel_url)\n",
    "                channels.append(channel_url)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "    next_page_link=soup.find('a',id='pnnext')\n",
    "    if next_page_link:\n",
    "        url='https://www.google.com'+next_page_link['href']\n",
    "    else:\n",
    "        print('all pages search completed')\n",
    "        break\n",
    "        \n",
    "print(channels)\n",
    "#save the data in json file \n",
    "data={'channels':channels}\n",
    "with open('youtube_channel_links.json','w') as file:\n",
    "    json.dump(data,file)\n",
    "    \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983acf77",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
